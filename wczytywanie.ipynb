{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_params_entry(row, columns):\n",
    "\n",
    "    \"\"\"\n",
    "    zmienna columns dostaje kolejne nazwy do bardziej \"globalnej\" zmiennej\n",
    "    a zwracana jest lista z wartościami kolejnej obserwacji\n",
    "    \"\"\"\n",
    "\n",
    "    entry = []\n",
    "    unordered = {} # wartości początkowo nie są posortowane bo stopniowo są dodawane nazwami a nie kolejnością\n",
    "    for param in row.split(\"<br>\"):\n",
    "        \n",
    "        key_value = param.split(\"<=>\")\n",
    "\n",
    "        # pomija parametry bez wartości\n",
    "        no_value = len(key_value) == 1\n",
    "        if (no_value):\n",
    "            continue\n",
    "\n",
    "        key = key_value[0]\n",
    "\n",
    "        # niektóre zmienne kończą się na _types i mają wtedy wiele możliwości które się dodatkowo łączą\n",
    "        # tutaj są zamieniane na zmienne binarne\n",
    "        if (key.endswith(\"types\")):\n",
    "            \n",
    "            if key_value[1].strip() == \"\" or key_value[1].strip() == \"0\":\n",
    "                continue\n",
    "\n",
    "            for value in key_value[1].split(\"<->\"):\n",
    "\n",
    "                real_key = key + \"_\" + value\n",
    "                if real_key not in columns:\n",
    "                    columns.append(real_key)\n",
    "                unordered[real_key] = True\n",
    "            continue\n",
    "        \n",
    "        # dodaje nazwę parametru do nagłówka\n",
    "        value = key_value[1]\n",
    "        if key not in columns:\n",
    "            columns.append(key)\n",
    "\n",
    "        unordered[key] = value\n",
    "\n",
    "    for key in columns:\n",
    "        entry.append(unordered[key] if key in unordered else None)    \n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, param_name = \"params\", nchunks = None, drop = [], chunksize = 10000):\n",
    "\n",
    "    \"\"\"\n",
    "    zbiera parametry w formacie <key><=>value<->value<->value<br>key><=>value<->... z DataFrame,\n",
    "    >>> parse_params(df)\n",
    "    id    price[currency]       m rooms_num     market  ... fence_types heating_types access_types vicinity_types is_bungalow\n",
    "    325017             PLN   72.14         4  secondary  ...        None          None         None           None        None\n",
    "    drop określa które kolumny wykluczyć ze wczytywania\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas\n",
    "\n",
    "    param_cols = []\n",
    "    csv_entries = []\n",
    "\n",
    "    print('Ładowanie wierszy:')\n",
    "    empty = pandas.read_csv(path, nrows=0).columns.drop(drop)\n",
    "                                                 # drop wybrane kolumny\n",
    "    \n",
    "    # iterator sprawia że w trakcie ładowania pliku przeprowadzane są od razu działania\n",
    "    iterator = pandas.read_csv(path, chunksize=chunksize, usecols=empty)\n",
    "                                                        # usecols sprawia że tylko wybrane kolumny są wczytane\n",
    "    for (k, chunk) in enumerate(iterator):\n",
    "\n",
    "        if (nchunks is not None and k >= nchunks):\n",
    "            break      \n",
    "        for (i, row) in chunk.iterrows():\n",
    "            \n",
    "            entry = parse_params_entry(row[param_name], param_cols)\n",
    "            csv_entries.append([*row.drop(param_name), *entry])\n",
    "\n",
    "        print(f'{(k+1)*10}k', end='\\n' if ((k+1)%10 == 0) else ' ')\n",
    "    \n",
    "    from pandas import DataFrame\n",
    "\n",
    "    return DataFrame(csv_entries, columns=[*empty.drop(param_name), *param_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ładowanie wierszy:\n",
      "10k 20k 30k 40k 50k 60k 70k 80k 90k 100k\n",
      "110k 120k 130k 140k 150k 160k 170k 180k 190k 200k\n",
      "210k 220k 230k 240k 250k 260k 270k 280k 290k 300k\n",
      "310k 320k 330k 340k 350k 360k 370k 380k 390k 400k\n",
      "410k 420k 430k 440k 450k 460k 470k 480k 490k 500k\n",
      "510k 520k 530k 540k 550k 560k 570k 580k 590k 600k\n",
      "610k 620k 630k 640k 650k 660k 670k 680k 690k 700k\n",
      "710k 720k 730k 740k 750k 760k 770k 780k 790k 800k\n",
      "810k 820k 830k 840k "
     ]
    }
   ],
   "source": [
    "df = read_data('train.csv', drop = ['description', 'title'])\n",
    "                          # drop - pomijamy kolumny tekstowe\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lon_lat_inplace(df, type = 'city', path = 'cities.csv'):\n",
    "    \n",
    "    import pandas\n",
    "    \n",
    "    cities = pandas.read_csv(path)[['id','lon','lat']]\n",
    "    cities.rename(columns= {\"id\" : f'{type}_id', 'lon': f'{type}_lon', 'lat': f'{type}_lat'}, inplace=True)\n",
    "    \n",
    "    df = pandas.merge(df, cities, on = f'{type}_id', how='left')\n",
    "\n",
    "get_lon_lat_inplace(df, 'city', 'cities.csv')\n",
    "get_lon_lat_inplace(df, 'district', 'districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['city_id', 'region_id', 'district_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
